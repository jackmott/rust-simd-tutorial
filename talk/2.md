# How to leverage SIMD Instructions
### 1. Let the compiler figure it out (auto vectorization)

```rust
// Good chance the compiler will figure this one out
let mut sum = 0;
for i in 0 .. BIGNUM {
    sum += ints[i];
}

// Only if you can tell the compiler floats are ok to vectorize
let mut sum = 0.0;
for i in 0 .. BIGNUM {
    sum += floats[i];
}

// Not likely
let mut funny_sum = 0;
for i in 0 .. BIGNUM {
    if ints[i] > 0 {
        funny_sum += ints[i];
    } else {
        funny_sum -= ints[i];
    }
}

```
### 2. Massage your code to help the compiler figure it out

```rust
let mut funny_sum = 0;
for i in 0 .. BIGNUM {        
    let bit_mask = (x[i] > 0) as u32 * 0xFFFFFFFF;
    let result = (bit_mask & ints[i]) | (!bit_mask & -ints[i]);
    funny_sum += result;    
}

```
### 3. Use assembler
```asm
    movups xmm0, [v1]  
    movups xmm1, [v2]  
    addps xmm0, xmm1   
    movups [v3], xmm0  
```
### 4. Use libraries or special tools (faster, packed_simd, bsimd, ispc)
```rust
//faster crate
let lots_of_3s = (&[-123.456f32; 128][..]).simd_iter()
    .simd_map(f32s(0.0), |v| {
        f32s(9.0) * v.abs().sqrt().rsqrt().ceil().sqrt() - f32s(4.0) - f32s(2.0)
    }).scalar_collect();
```

### 5. Intrinsics!
```rust
 let a = _mm_loadu_ps(a_arr[i] as *const f32);
 let b = _mm_loadu_ps(b_arr[i] as *const f32);
_mm_storeu_ps(&mut result[i] as *mut f32,_mm_add_ps(selfx,bx));                                    
```